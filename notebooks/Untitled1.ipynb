{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5dee2d-c714-4c19-9daf-95e21eed105b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/site-packages (4.38.1)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/site-packages (0.15.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/site-packages (from torch) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/site-packages (from torch) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers tokenizers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d0d2fb-47f7-4f48-b823-43a65fa69d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/salesforce/progen.git\n",
    "# !git clone https://github.com/joethequant/docker_protein_generator.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d359b0c-18b8-4fbb-8c78-d615004cddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/src/docker_protein_generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd docker_protein_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4fa30df-ff71-4fb1-94e6-b493f40fce01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  README.md  build_and_push.sh  requirements.txt  test_input.json\n",
      "LICENSE     app.py     \u001b[0m\u001b[01;34mmodels\u001b[0m/            running.ipynb     tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be927297-ccaa-4c12-ad16-048d16e7079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.progen.modeling_progen import ProGenForCausalLM\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f701ba-9b1e-4b4d-b8ab-d932632c4b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model \n",
    "model_path = 'AntibodyGeneration/fine-tuned-progen2-small'\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = ProGenForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = Tokenizer.from_file('tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b0f2db4-b7b1-471a-b4e1-c55932873181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your sequence and other parameters\n",
    "target_sequence = 'MQIPQAPWPVVWAVLQLGWRPGWFLDSPDRPWNPPTFSPALLVVTEGDNATFTCSFSNTSESFVLNWYRMSPSNQTDKLAAFPEDRSQPGQDCRFRVTQLPNGRDFHMSVVRARRNDSGTYLCGAISLAPKAQIKESLRAELRVTERRAEVPTAHPSPSPRPAGQFQTLVVGVVGGLLGSLVLLVWVLAVICSRAARGTIGARRTGQPLKEDPSAVPVFSVDYGELDFQWREKTPEPPVPCVPEQTEYATIVFPSGMGTSSPARRGSADGPRSAQPLRPEDGHCSWPL'\n",
    "number_of_sequences = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b16024-e4b0-4b74-9556-487d908cb025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sequence\n",
    "tokenized_sequence = tokenizer.encode(target_sequence)\n",
    "\n",
    "# Convert to PyTorch tensor and add batch dimension\n",
    "input_tensor = torch.tensor([tokenized_sequence.ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f2d69b3-c49c-4375-81d9-c5acf889f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model.generate(input_tensor, max_length=1024, pad_token_id=tokenizer.encode('<|pad|>').ids[0], do_sample=True, top_p=0.9, temperature=0.8, num_return_sequences=number_of_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7350e95f-0428-4692-9dc8-4c3f66b266b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sequences\n",
    "# with torch.no_grad():\n",
    "#     output = model.generate(**tokenized_sequence, max_length=1024, pad_token_id=tokenizer.pad_token_id, do_sample=True, top_p=0.9, temperature=0.8, num_return_sequences=number_of_sequences)\n",
    "\n",
    "# # # Pass the tensor through the model\n",
    "with torch.no_grad():\n",
    "    output = model.generate(input_tensor, max_length=1024, pad_token_id=tokenizer.encode('<|pad|>').ids[0], do_sample=True, top_p=0.9, temperature=0.8, num_return_sequences=number_of_sequences)\n",
    "# # Decoding the output to get generated sequences\n",
    "# generated_sequences = [tokenizer.decode(output_seq, skip_special_tokens=True) for output_seq in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926dc6bf-fabb-45d3-ba2e-b970cc07d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac9277-c278-4cab-b62f-3d8be837de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from progen.progen2.models.progen.modeling_progen import ProGenForCausalLM\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd6feb-6aaa-4c84-82d7-af6a10cdb2b9",
   "metadata": {},
   "source": [
    "https://github.com/joethequant/docker_protein_generator/blob/main/app.py\n",
    "\n",
    "\n",
    "https://huggingface.co/AntibodyGeneration/fine-tuned-progen2-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd6e7b-3dc8-4521-aa76-36488a9beabc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
