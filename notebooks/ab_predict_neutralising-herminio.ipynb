{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c573c48-6146-4487-ae68-68d277fa87f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The selected model to use (heavy) does not exist.        Please select a valid model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mablang2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# heavy chain sequence\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m heavy_ablang \u001b[38;5;241m=\u001b[39m \u001b[43mablang2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheavy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m heavy_ablang\u001b[38;5;241m.\u001b[39mfreeze()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ablang2/pretrained.py:26\u001b[0m, in \u001b[0;36mpretrained.__init__\u001b[0;34m(self, model_to_use, random_init, ncpu, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(device)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAbLang, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_use\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAbLang\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_device)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mAbLang\u001b[38;5;241m.\u001b[39meval() \u001b[38;5;66;03m# Default \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/ablang2/load_model.py:35\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_to_use, random_init, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m     AbLang, tokenizer, hparams \u001b[38;5;241m=\u001b[39m fetch_ablang2(\n\u001b[1;32m     30\u001b[0m         model_to_use, \n\u001b[1;32m     31\u001b[0m         random_init\u001b[38;5;241m=\u001b[39mrandom_init, \n\u001b[1;32m     32\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     33\u001b[0m     )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe selected model to use (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_to_use\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) does not exist.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124m    Please select a valid model.\u001b[39m\u001b[38;5;124m\"\u001b[39m   \n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m AbLang, tokenizer, hparams\n",
      "\u001b[0;31mAssertionError\u001b[0m: The selected model to use (heavy) does not exist.        Please select a valid model."
     ]
    }
   ],
   "source": [
    "import ablang2\n",
    "\n",
    "# heavy chain sequence\n",
    "heavy_ablang = ablang2.pretrained(\"heavy\")\n",
    "heavy_ablang.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e6dabd-24ad-456c-9d8f-c0c7e8dd2ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 3000\n",
      "['EVQLVQSGAEVSQPGESLKISCKGSGYSFTGYWISWVRQMPGKGLEWMGIIYPGDSDTKYTPSFQGQVTISTDKSINTAYLQWSSLKASDTAMYYCARRGDGLYYYGMDVWGQGTTVTVSS', 'EVQLVESGPGLVKPSETLSLTCTASGGSISTYYWSWIRQPPGKGLEWIGYIYYSGSTNYNPSLKSRVTISVDTSKNQFSLKLSSVTAADTAVYYCARDRIAPVGKFFGWYFDLWGRGTLVTVSS']\n",
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7E3K', '', '', '', '', '', '', '', '', '', '', '', '', '7E5Y', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7AKD', '', '', '7C2L', '', '', '', '', '', '', '', '', '7T01', '', '', '', '', '', '', '', '', '', '', '2GHW', '', '7DZX', '', '', '', '', '', '', '', '', '', '', '7KS9', '', '', '', '', '', '', '7TC9', '7TB8', '7LRS', '7F3Q', '7F3Q', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7MJJ', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7E39', '', '', '', '', '', '7E3B', '', '', '7WS4', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7E3L', '', '', '', '', '', '', '', '', '', '', '', '7U2E', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7M7B', '7KQB', '7L7E', '7L7D', '', '', '7MLZ', '', '', '7BZ5', '', '7KMG', '', '', '7CHB', '', '', '', '', '', '', '7CHC', '', '', '', '', '', '', '', '', '', '', '7EK0', '7E86', '7E88', '', '', '', '', '7CH4', '', '', '', '', '', '', '', '7E7Y', '', '7CH5', '', '7EY4', '', '', '', '', '', '', '', '', '', '', '', '', '', '7EY0', '', '', '', '', '', '', '7EY5', '', '', '', '', '7EYA', '', '', '', '7EZV', '7EY0', '', '', '', '', '7EY5', '', '', '', '', '', '', '', '7EZV', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7BYR', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7WRL', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '7WR8', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./covabdab_all.csv\")\n",
    "\n",
    "# get the heavy chain sequence \"seqs\", the neutralising data (0 or 1) \"neutralising\", and PDB IDs \"pdbids\"\n",
    "seqs = []\n",
    "neutralising = []\n",
    "pdbids = []\n",
    "\n",
    "frame_size = len(df.index)\n",
    "\n",
    "# There are some problems in some sequences,let's try the first 3000 records for now\n",
    "#MAXCNT = frame_size\n",
    "MAXCNT = 3000\n",
    "\n",
    "cnt = 0\n",
    "for i in range(frame_size):\n",
    "    if (cnt < MAXCNT and str(df.iloc[i]['Origin']).lower().find('human') != -1 and df.iloc[i]['VHorVHH'] != 'ND'):\n",
    "        seqs.append(df.iloc[i]['VHorVHH'])\n",
    "        # somehow the empty string became \"nan\"\n",
    "        if(str(df.iloc[i]['Neutralising Vs']) != \"nan\"):\n",
    "            neutralising.append(1)\n",
    "        else:\n",
    "            neutralising.append(0)\n",
    "            \n",
    "        if(str(df.iloc[i]['Structures']).find('PDB entry') != -1):\n",
    "            pdbids.append(str(df.iloc[i]['Structures'])[10:14])\n",
    "        else:\n",
    "            pdbids.append('')\n",
    "            \n",
    "        cnt = cnt + 1\n",
    "\n",
    "print (\"Lines:\", len(seqs))\n",
    "print (seqs[0:2])\n",
    "print (neutralising)\n",
    "print (pdbids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d842cd2-f442-43be-865b-98d7e1492fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output shape of the seq-codings: (3000, 768)\n",
      "[[-0.09330826  0.64819845 -1.08619225 ... -0.59027605  0.34280308\n",
      "   0.80515875]\n",
      " [-0.45837705  0.50708104 -1.15761436 ... -0.21607836  0.77288645\n",
      "   1.13230815]\n",
      " [-0.39963617  0.87048231 -0.38694611 ... -0.74714346  0.69520932\n",
      "   1.18203556]\n",
      " ...\n",
      " [-0.19876792 -0.24587346 -1.34513009 ... -0.44275984  0.05823695\n",
      "   0.58274662]\n",
      " [-0.35545545  0.04221355 -0.81353943 ... -0.73681659  0.10114052\n",
      "   1.01259486]\n",
      " [-0.31492943  0.15609218 -0.74546616 ... -0.42618225  0.45762792\n",
      "   0.83552733]]\n"
     ]
    }
   ],
   "source": [
    "# use the \"Seq-coding\" example to get an array for each sequence\n",
    "seqcodings = heavy_ablang(seqs, mode='seqcoding')\n",
    "\n",
    "print(\"The output shape of the seq-codings:\", seqcodings.shape)\n",
    "\n",
    "print(seqcodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82cacafa-ec8f-4c07-9304-3134877e9e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 17:55:00.093853: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:00.093884: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.9.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pip install tensorflow\n",
    "\n",
    "# Use the Artificial Neuron Network (ANN) to train the model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286942f6-348f-457c-8797-a8d9a91d61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(seqcodings, neutralising, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bd0ff91-72dd-4a84-990d-9fe93a46900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "123d219b-10a8-498e-ba99-07550c494fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 17:55:04.568980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 17:55:04.569336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.569417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.569471: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.569523: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.569573: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.570479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.571224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.572362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-08-10 17:55:04.572371: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-10 17:55:04.573241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Initializing the ANN\n",
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "303d9818-350d-4062-9d86-dc48bd4c5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ff3aea-ee20-4c22-93b4-cc4289672a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe22fc2-acd9-473f-a126-7565a1ebeff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759e4257-88cc-41d6-b074-0559ba96a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "258b17dd-09d6-45ae-ba2d-fd86764f5a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 1s 1ms/step - loss: 0.4886 - accuracy: 0.7738\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.7954\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.4076 - accuracy: 0.7996\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3920 - accuracy: 0.8029\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8183\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3692 - accuracy: 0.8225\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8267\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3466 - accuracy: 0.8363\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3398 - accuracy: 0.8325\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3297 - accuracy: 0.8496\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3239 - accuracy: 0.8496\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3142 - accuracy: 0.8525\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8554\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2982 - accuracy: 0.8612\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2965 - accuracy: 0.8687\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8758\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2812 - accuracy: 0.8717\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2719 - accuracy: 0.8821\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2630 - accuracy: 0.8846\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2584 - accuracy: 0.8796\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2544 - accuracy: 0.8883\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.8925\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.8942\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.8921\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2295 - accuracy: 0.8992\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.9004\n",
      "Epoch 27/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.9021\n",
      "Epoch 28/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9108\n",
      "Epoch 29/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.9117\n",
      "Epoch 30/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.2016 - accuracy: 0.9079\n",
      "Epoch 31/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.9146\n",
      "Epoch 32/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.9137\n",
      "Epoch 33/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.9158\n",
      "Epoch 34/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.9262\n",
      "Epoch 35/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.9267\n",
      "Epoch 36/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1701 - accuracy: 0.9317\n",
      "Epoch 37/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1628 - accuracy: 0.9350\n",
      "Epoch 38/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9346\n",
      "Epoch 39/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9358\n",
      "Epoch 40/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9350\n",
      "Epoch 41/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1486 - accuracy: 0.9413\n",
      "Epoch 42/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1413 - accuracy: 0.9425\n",
      "Epoch 43/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9362\n",
      "Epoch 44/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.9475\n",
      "Epoch 45/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1336 - accuracy: 0.9479\n",
      "Epoch 46/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1322 - accuracy: 0.9488\n",
      "Epoch 47/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.9554\n",
      "Epoch 48/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9571\n",
      "Epoch 49/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9538\n",
      "Epoch 50/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9575\n",
      "Epoch 51/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9613\n",
      "Epoch 52/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1123 - accuracy: 0.9567\n",
      "Epoch 53/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9658\n",
      "Epoch 54/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9625\n",
      "Epoch 55/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1025 - accuracy: 0.9675\n",
      "Epoch 56/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.1005 - accuracy: 0.9663\n",
      "Epoch 57/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.9696\n",
      "Epoch 58/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9683\n",
      "Epoch 59/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9733\n",
      "Epoch 60/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0866 - accuracy: 0.9733\n",
      "Epoch 61/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0890 - accuracy: 0.9721\n",
      "Epoch 62/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.9696\n",
      "Epoch 63/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0888 - accuracy: 0.9712\n",
      "Epoch 64/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0870 - accuracy: 0.9712\n",
      "Epoch 65/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9717\n",
      "Epoch 66/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 0.9771\n",
      "Epoch 67/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9771\n",
      "Epoch 68/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9771\n",
      "Epoch 69/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9808\n",
      "Epoch 70/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0703 - accuracy: 0.9804\n",
      "Epoch 71/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9792\n",
      "Epoch 72/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9842\n",
      "Epoch 73/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9825\n",
      "Epoch 74/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9821\n",
      "Epoch 75/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9858\n",
      "Epoch 76/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9879\n",
      "Epoch 78/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9871\n",
      "Epoch 80/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0551 - accuracy: 0.9858\n",
      "Epoch 81/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0452 - accuracy: 0.9896\n",
      "Epoch 82/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9883\n",
      "Epoch 83/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9892\n",
      "Epoch 84/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9892\n",
      "Epoch 85/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0478 - accuracy: 0.9879\n",
      "Epoch 86/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9858\n",
      "Epoch 87/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0455 - accuracy: 0.9900\n",
      "Epoch 88/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9779\n",
      "Epoch 89/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9754\n",
      "Epoch 90/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9737\n",
      "Epoch 91/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0442 - accuracy: 0.9875\n",
      "Epoch 92/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9892\n",
      "Epoch 93/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9933\n",
      "Epoch 94/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9929\n",
      "Epoch 95/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0344 - accuracy: 0.9925\n",
      "Epoch 96/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9929\n",
      "Epoch 97/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9933\n",
      "Epoch 98/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9925\n",
      "Epoch 99/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9917\n",
      "Epoch 100/100\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5c7cc5bfa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the ANN on the Training set\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff819d31-8e7c-463e-b3f3-f54c386d5a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 2400 [[ 1.91177638 -1.37914301 -0.01711973 ...  0.071948   -0.86682257\n",
      "   1.04885515]\n",
      " [ 0.40828873  1.66285426  0.7683436  ... -0.14606984 -0.21671683\n",
      "   0.77387369]\n",
      " [ 0.06129879  0.64096578  0.14537357 ...  0.17819591  0.71597356\n",
      "   0.83455625]\n",
      " ...\n",
      " [ 0.15100135 -0.2044245   1.26322577 ...  0.16612532 -0.21241946\n",
      "  -0.38830657]\n",
      " [-0.62988971 -2.59805259 -1.31028852 ...  0.01790867 -0.67751233\n",
      "   0.78994512]\n",
      " [ 1.70490741 -1.89280508  0.17699117 ...  0.29894609  0.09576332\n",
      "  -1.10152332]]\n"
     ]
    }
   ],
   "source": [
    "print (\"len:\", len(X_train), X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ca3b28-8604-427f-bc27-13a7dbe4f832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 600 [[ 0.16025759  0.35031499 -0.308193   ... -0.82382215 -0.89080491\n",
      "   0.84782852]\n",
      " [-0.2162426  -0.32633827  0.88079547 ... -1.40541159  0.15737595\n",
      "  -0.05270441]\n",
      " [ 0.14510934 -3.11858044  0.92736741 ...  0.70652506 -0.38064735\n",
      "  -0.36117366]\n",
      " ...\n",
      " [-0.31979006  0.34694813  0.75015523 ...  1.15863723  0.87475739\n",
      "  -0.42168111]\n",
      " [-1.76719913 -1.32080877  0.123102   ... -1.58562114 -0.34928527\n",
      "  -1.59780679]\n",
      " [-0.87844641 -0.4222064   0.37687927 ... -0.39090743 -0.81173503\n",
      "   1.14218592]]\n"
     ]
    }
   ],
   "source": [
    "print (\"len:\", len(X_test), X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781b6e64-0e7b-4d31-99d3-212930a50714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 600 [0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print (\"len:\", len(y_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "132dde1b-0e60-4529-bed0-4000f0881fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 834us/step\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "#print (\"len:\", len(y_pred), y_pred)\n",
    "\n",
    "#print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80f5b60b-eed8-45b4-af88-e47b52b286a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[402  73]\n",
      " [ 57  68]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7833333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8933a2ff-a935-4786-b5b9-58a8d3590283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB ID: 7M7B seq: QVQLQQWGAGLLKPSETLSLTCAVYGGSFSGYYWSWIRQPPGKGLEWIGEINHSGSTNYNPSLKSRVTISVDTSKNQFSLKLSSVTAADTAVYYCARRWWLRGAFDIWGQGTTVTVSS\n",
      "totalCnt: 600 matchCnt: 470 Matched ratio: 0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "#pip install icn3dpy\n",
    "#pip install jupyterlab\n",
    "#jupyterhub labextension install jupyterlab_3dmol\n",
    "\n",
    "# show 3D structure\n",
    "\n",
    "import icn3dpy\n",
    "\n",
    "offset = int(MAXCNT * 0.8)\n",
    "matchCnt = 0\n",
    "totalCnt = len(y_pred)\n",
    "bFound = False\n",
    "for i in range(totalCnt):\n",
    "    if(y_pred[i] == y_test[i]):\n",
    "        matchCnt = matchCnt + 1\n",
    "\n",
    "    if(pdbids[i+offset] != '' and bFound == False):\n",
    "        bFound = True\n",
    "        pdbid = pdbids[i+offset]\n",
    "        seq = seqs[i+offset]\n",
    "        print (\"PDB ID:\", pdbid, \"seq:\", seq)\n",
    "        idStr = 'mmdbid=' + pdbid\n",
    "        cmdStr = 'select :' + seq + ' | name test; color F00; style proteins sphere'\n",
    "        view = icn3dpy.view(q=idStr,command=cmdStr)\n",
    "        view\n",
    "        \n",
    "print(\"totalCnt:\", totalCnt, \"matchCnt:\", matchCnt, \"Matched ratio:\", matchCnt/totalCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a62855a-8e3b-402e-86d8-6870b83bb37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmdbid=7M7B select :QVQLQQWGAGLLKPSETLSLTCAVYGGSFSGYYWSWIRQPPGKGLEWIGEINHSGSTNYNPSLKSRVTISVDTSKNQFSLKLSSVTAADTAVYYCARRWWLRGAFDIWGQGTTVTVSS | name test; color F00; style proteins sphere\n"
     ]
    }
   ],
   "source": [
    "idStr = 'mmdbid=' + pdbid\n",
    "cmdStr = 'select :' + seq + ' | name test; color F00; style proteins sphere'\n",
    "print (idStr, cmdStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "565ed11c-ff6f-43d0-bdb1-129c06b54aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/3dmoljs_load.v0": "<div id=\"icn3dviewer16601544591159678\" style=\"position: relative; width: 640px; min-height: 580px; height: auto\">\n        <p id=\"icn3dwarning16601544591159678\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the extension: <br>\n        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n        </div>\n<script>\n\nvar loadScriptAsync = function(uri){\n  return new Promise((resolve, reject) => {\n    var tag = document.createElement('script');\n    tag.src = uri;\n    //tag.async = true;\n    tag.onload = () => {\n      resolve();\n    };\n  var firstScriptTag = document.getElementsByTagName('link')[0];\n  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n  });\n};\n\nvar loadCssAsync = function(uri){\n  return new Promise((resolve, reject) => {\nvar tag = document.createElement('link');\ntag.rel = 'stylesheet';\ntag.href = uri;\n//tag.async = true;\ntag.onload = () => {\n  resolve();\n};\nvar firstScriptTag = document.getElementsByTagName('script')[0];\nfirstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n  });\n};\n\nif(typeof js === 'undefined') {\n  js = loadScriptAsync(\"https://www.ncbi.nlm.nih.gov/Structure/icn3d/es5/icn3d_all_full.min.js\");\n  \n  css1 = loadCssAsync(\"https://www.ncbi.nlm.nih.gov/Structure/icn3d/lib/jquery-ui-1.13.2.min.css\");\n  css2 = loadCssAsync(\"https://www.ncbi.nlm.nih.gov/Structure/icn3d/icn3d.css\");\n}\n\nvar viewer16601544591159678 = null;\nvar warn = document.getElementById(\"icn3dwarning16601544591159678\");\nif(warn) {\n    warn.parentNode.removeChild(warn);\n}\n\ncss1\n.then(function() { return css2; })\n.then(function() { return js; })\n.then(function() {\ncfg = {divid: \"icn3dviewer16601544591159678\", mmdbid: \"7M7B\", width: \"640px\", height: \"480px\", mobilemenu: 1, notebook: 1, command: 'select :QVQLQQWGAGLLKPSETLSLTCAVYGGSFSGYYWSWIRQPPGKGLEWIGEINHSGSTNYNPSLKSRVTISVDTSKNQFSLKLSSVTAADTAVYYCARRWWLRGAFDIWGQGTTVTVSS | name test; color F00; style proteins sphere', };\nviewer16601544591159678 = new icn3d.iCn3DUI(cfg);\nviewer16601544591159678.show3DStructure();\n});\n</script>",
      "text/html": [
       "<div id=\"icn3dviewer16601544591159678\" style=\"position: relative; width: 640px; min-height: 580px; height: auto\">\n",
       "        <p id=\"icn3dwarning16601544591159678\" style=\"background-color:#ffcccc;color:black\">You appear to be running in JupyterLab (or JavaScript failed to load for some other reason).  You need to install the extension: <br>\n",
       "        <tt>jupyter labextension install jupyterlab_3dmol</tt></p>\n",
       "        </div>\n",
       "<script>\n",
       "\n",
       "var loadScriptAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "    var tag = document.createElement('script');\n",
       "    tag.src = uri;\n",
       "    //tag.async = true;\n",
       "    tag.onload = () => {\n",
       "      resolve();\n",
       "    };\n",
       "  var firstScriptTag = document.getElementsByTagName('link')[0];\n",
       "  firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "  });\n",
       "};\n",
       "\n",
       "var loadCssAsync = function(uri){\n",
       "  return new Promise((resolve, reject) => {\n",
       "var tag = document.createElement('link');\n",
       "tag.rel = 'stylesheet';\n",
       "tag.href = uri;\n",
       "//tag.async = true;\n",
       "tag.onload = () => {\n",
       "  resolve();\n",
       "};\n",
       "var firstScriptTag = document.getElementsByTagName('script')[0];\n",
       "firstScriptTag.parentNode.insertBefore(tag, firstScriptTag);\n",
       "  });\n",
       "};\n",
       "\n",
       "if(typeof js === 'undefined') {\n",
       "  js = loadScriptAsync(\"https://www.ncbi.nlm.nih.gov/Structure/icn3d/es5/icn3d_all_full.min.js\");\n",
       "  \n",
       "  css1 = loadCssAsync(\"https://www.ncbi.nlm.nih.gov/Structure/icn3d/lib/jquery-ui-1.13.2.min.css\");\n",
       "  css2 = loadCssAsync(\"https://www.ncbi.nlm.nih.gov/Structure/icn3d/icn3d.css\");\n",
       "}\n",
       "\n",
       "var viewer16601544591159678 = null;\n",
       "var warn = document.getElementById(\"icn3dwarning16601544591159678\");\n",
       "if(warn) {\n",
       "    warn.parentNode.removeChild(warn);\n",
       "}\n",
       "\n",
       "css1\n",
       ".then(function() { return css2; })\n",
       ".then(function() { return js; })\n",
       ".then(function() {\n",
       "cfg = {divid: \"icn3dviewer16601544591159678\", mmdbid: \"7M7B\", width: \"640px\", height: \"480px\", mobilemenu: 1, notebook: 1, command: 'select :QVQLQQWGAGLLKPSETLSLTCAVYGGSFSGYYWSWIRQPPGKGLEWIGEINHSGSTNYNPSLKSRVTISVDTSKNQFSLKLSSVTAADTAVYYCARRWWLRGAFDIWGQGTTVTVSS | name test; color F00; style proteins sphere', };\n",
       "viewer16601544591159678 = new icn3d.iCn3DUI(cfg);\n",
       "viewer16601544591159678.show3DStructure();\n",
       "});\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<icn3dpy.view at 0x7f5c7cba75b0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view = icn3dpy.view(q=idStr,command=cmdStr)\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a016b3d-ed13-436d-883b-ddbd36c1315c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
